{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal extraction with Gemini-Flash-1.5 ðŸ“¸ & Langchain â›“ï¸â€ðŸ’¥\n",
    "In this notebook we will demo how to use the Gemini-Flash-1.5 model to extract entities from a given text. The model is a multi-modal model that can extract entities from both text and images.\n",
    "\n",
    "In this example notebook we will touch on the following topics:\n",
    "1. Extracting image metadata using Langchain and Gemini-Flash-1.5\n",
    "2. Running the extraction process in parallel across all images in a dataset\n",
    "3. Add variation to the generated text without using the model temperature parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images to extract data from\n",
    "fruits = ['https://storage.googleapis.com/vectrix-public/fruit/apple.jpeg',\n",
    "          'https://storage.googleapis.com/vectrix-public/fruit/banana.jpeg',\n",
    "          'https://storage.googleapis.com/vectrix-public/fruit/kiwi.jpeg',\n",
    "          'https://storage.googleapis.com/vectrix-public/fruit/peach.jpeg',\n",
    "          'https://storage.googleapis.com/vectrix-public/fruit/plum.jpeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing an image directly to the model\n",
    "[As described in the LangChain documentation](https://python.langchain.com/v0.2/docs/how_to/multimodal_inputs/), we can use the code below to directly pass an image to the model. This will pass our multi-modal input along with out chat contents to the model.\n",
    "\n",
    "The code is the same for other LLMs like GPT4o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fruit is a red and yellow apple. It has a dimple in the middle and is slightly bruised.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import base64, httpx\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "image_data = base64.b64encode(httpx.get(fruits[0]).content).decode(\"utf-8\")\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"describe the fruit in this image\"},\n",
    "        {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response = model.invoke([message])\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3972324"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting structured data from images\n",
    "The next step is to extract structured data from the image. We can achieve this by combining a [Pydantic parser](https://python.langchain.com/v0.1/docs/modules/model_io/output_parsers/types/pydantic/) with a multi-modal message. First we define a Pydantic data model and we will then pass that to the model to extract structured data from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Apricot\",\n",
      "  \"color\": \"Orange\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"A juicy and flavorful apricot, perfect for a summer snack or dessert.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "\n",
    "class Fruit(BaseModel):\n",
    "    name: str = Field(description=\"The name of the fruit shown in the image\")\n",
    "    color: str = Field(description=\"The color of the fruit shown in the image\")\n",
    "    taste: str = Field(description=\"The taste of the fruit shown in the image\")\n",
    "    marketing_description: str = Field(description=\"A marketing description of the fruit shown in the image\")\n",
    "\n",
    "    @classmethod\n",
    "    def model_json_schema(cls):\n",
    "        return json.loads(cls.schema_json())\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Fruit)\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\"Return the requested response object in {language}.\\n'{format_instructions}'\\n\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\", [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "])\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Retrieve the encoded image data\n",
    "image_data = base64.b64encode(httpx.get(fruits[3]).content).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# Run the chain and print the result\n",
    "print(chain.invoke({\"language\":\"English\",\n",
    "                    \"format_instructions\":parser.get_format_instructions(),\n",
    "                    \"image_data\":image_data}).json(indent=2),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing all images in parallel and translating the description in two languages\n",
    "In this example notebook we only have 5 images, but in the case you want to run this on a larger dataset, running this using a regular for loop would be very slow. So, we use Langchains built-in parallel processing capabilities to process all images in parallel.\n",
    "\n",
    "### Run the requests from above in parallel\n",
    "By using chain.batch we can now run the extraction process for all the images in parallel. This will be much faster than running the requests sequentially.\n",
    "\n",
    "Also note that we use the all_images list of dictionaries to feed the chain.batch function. This is because the chain.batch function expects a list of dictionaries as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Apple\",\n",
      "  \"color\": \"Red and green\",\n",
      "  \"taste\": \"Sweet and tart\",\n",
      "  \"marketing_description\": \"A crisp and juicy apple with a perfect balance of sweet and tart flavors. Enjoy it fresh, in salads, or baked into delicious desserts.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Banana\",\n",
      "  \"color\": \"Yellow\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"A delicious and nutritious fruit, perfect for a healthy snack or a tasty addition to your breakfast.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Kiwi\",\n",
      "  \"color\": \"Green\",\n",
      "  \"taste\": \"Sweet and tangy\",\n",
      "  \"marketing_description\": \"The kiwi is a delicious and healthy fruit that is packed with nutrients. It is a good source of vitamin C, potassium, and fiber. The kiwi has a unique flavor that is both sweet and tangy. It is a versatile fruit that can be enjoyed in many different ways, such as in smoothies, salads, or as a snack.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Apricot\",\n",
      "  \"color\": \"Orange\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"A juicy and flavorful apricot, perfect for a summer snack or dessert.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Plum\",\n",
      "  \"color\": \"Red\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"A juicy and sweet plum, perfect for a snack or dessert.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Now run this chain in parallel for all the images\n",
    "all_images = [{\"language\":\"English\", \n",
    "  \"format_instructions\": parser.get_format_instructions(),\n",
    "  \"image_data\":  base64.b64encode(httpx.get(url).content).decode(\"utf-8\")} for url in fruits]\n",
    "\n",
    "results = chain.batch(all_images, config={\"max_concurrency\": 5})\n",
    "\n",
    "for result in results:\n",
    "    print(result.json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create variations on the output data\n",
    "As seen in the examples above, all marketing descriptions start with the letter and the last two descriptions start very similar:\n",
    "> A juicy and flavorful apricot...\n",
    "\n",
    "> A juicy and flavorful plum...\n",
    "\n",
    "Output that is very similar is not great for SEO-purposes. For annotating images playing with the temperature of the model isn't the best way to get different results.\n",
    "\n",
    "#### Instead, we should write a function to forse the model to be more creative. We ask it to start the description with a certain letter and have a description with x amount of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Apple\",\n",
      "  \"color\": \"Red and Green\",\n",
      "  \"taste\": \"Sweet and Tart\",\n",
      "  \"marketing_description\": \"A crisp and juicy apple with a perfect balance of sweet and tart flavors. Enjoy it fresh, baked into a pie, or in a delicious salad.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Banana\",\n",
      "  \"color\": \"Yellow\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"Deliciously sweet and creamy, this banana is perfect for a quick snack or a healthy addition to your favorite smoothie.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Kiwi\",\n",
      "  \"color\": \"Green\",\n",
      "  \"taste\": \"Sweet and tangy\",\n",
      "  \"marketing_description\": \"The taste of sunshine! This kiwi is bursting with juicy, tangy flavor that's sure to brighten your day. Perfect for snacking, smoothies, or adding a touch of sweetness to your favorite dishes.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Apricot\",\n",
      "  \"color\": \"Orange\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"The apricot is a stone fruit with a sweet and juicy flavor. It's a popular choice for desserts, jams, and preserves. Apricots are also a good source of vitamin A and fiber.\"\n",
      "}\n",
      "{\n",
      "  \"name\": \"Plum\",\n",
      "  \"color\": \"Purple\",\n",
      "  \"taste\": \"Sweet\",\n",
      "  \"marketing_description\": \"Come and try our juicy, sweet plums! They are the perfect snack for any time of day.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_letter():\n",
    "    letters = ['A', 'B', 'C', 'D', 'M', 'P', 'R', 'S', 'T']\n",
    "    return str(random.choice(letters))\n",
    "\n",
    "def generate_random_number():\n",
    "    return int(random.randint(30, 45))\n",
    "\n",
    "\n",
    "\n",
    "# A new prompt template that includes the marketing description starting with a letter given in the variable\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\"Return the requested response object in {language}. Make sure the marketing description starts with the letter '{starting_letter}'\\n'{format_instructions}'\\n\"\n",
    "    ),\n",
    "    (\n",
    "        \"human\", [\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": \"data:image/jpeg;base64,{image_data}\"},\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "])\n",
    "\n",
    "# Now run this chain in parallel for all the images\n",
    "all_images = [{\"language\":\"English\", \n",
    "  \"format_instructions\": parser.get_format_instructions(),\n",
    "  \"image_data\":  base64.b64encode(httpx.get(url).content).decode(\"utf-8\"),\n",
    "  \"starting_letter\": generate_random_letter()} for url in fruits] # Make sure you add the starting letter as a variable for the call\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "\n",
    "\n",
    "results = chain.batch(all_images, config={\"max_concurrency\": 5})\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    print(result.json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digi-marketing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
